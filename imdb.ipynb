{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b1892e7-29b0-4c1d-b87f-874adb3a9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecc33bc1-9d36-432d-bbbe-34aafed5bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_features = 10000  # Number of most frequent words to consider\n",
    "max_len = 200  # Maximum review length (truncate or pad)\n",
    "batch_size = 32  # Reviews processed in each batch\n",
    "epochs = 10  # Training iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81539ed5-b16f-4c9c-8a05-18eb2e7193be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB dataset\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85a69ccf-7d09-469d-b4f9-5fc2391869ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to same length\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "104304ec-3d36-4329-bb68-e3a60b576cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding layer\n",
    "embedding_dim = 128  # Dimensionality of word embeddings\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dim, input_length=max_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "307290a1-6a8e-494e-9bd5-b88c050252a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LSTM layer for sequential processing\n",
    "model.add(LSTM(64))  # Adjust number of units as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93061527-efd5-4abf-a9b9-dbfa783be997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer with sigmoid activation for probability\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77b5e375-aa9c-4f3f-8937-1b6a56e8ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b27faaf-fa46-4bb5-b862-4b37bc8db13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 152ms/step - accuracy: 0.7307 - loss: 0.5127 - val_accuracy: 0.8326 - val_loss: 0.3771\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 173ms/step - accuracy: 0.8972 - loss: 0.2608 - val_accuracy: 0.8645 - val_loss: 0.3311\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 178ms/step - accuracy: 0.9348 - loss: 0.1765 - val_accuracy: 0.8731 - val_loss: 0.3307\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 185ms/step - accuracy: 0.9536 - loss: 0.1260 - val_accuracy: 0.8596 - val_loss: 0.3858\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 183ms/step - accuracy: 0.9638 - loss: 0.0981 - val_accuracy: 0.8651 - val_loss: 0.4519\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 161ms/step - accuracy: 0.9737 - loss: 0.0772 - val_accuracy: 0.8413 - val_loss: 0.5083\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 190ms/step - accuracy: 0.9596 - loss: 0.1057 - val_accuracy: 0.8591 - val_loss: 0.4798\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 173ms/step - accuracy: 0.9865 - loss: 0.0407 - val_accuracy: 0.8618 - val_loss: 0.5236\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 180ms/step - accuracy: 0.9935 - loss: 0.0222 - val_accuracy: 0.8511 - val_loss: 0.6519\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 187ms/step - accuracy: 0.9950 - loss: 0.0158 - val_accuracy: 0.8490 - val_loss: 0.7291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x741dc79319d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2b530-b9c9-4e49-8140-59f97346f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment for a new review\n",
    "new_review = \"This movie was fantastic!\"  # Preprocess the review similarly as training data\n",
    "new_review = pad_sequences([new_review.split()], maxlen=max_len)\n",
    "prediction = model.predict(new_review)\n",
    "sentiment = \"positive\" if prediction > 0.5 else \"negative\"\n",
    "print(\"Predicted sentiment:\", sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0467935a-e93b-4bb7-902c-58d1304cab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def predict_sentiment(model, review):\n",
    "  \"\"\"\n",
    "  Preprocesses user input review and predicts sentiment using the trained model.\n",
    "\n",
    "  Args:\n",
    "      model: Trained Keras model for sentiment classification.\n",
    "      review: User input review as a string.\n",
    "\n",
    "  Returns:\n",
    "      Predicted sentiment (\"positive\" or \"negative\")\n",
    "  \"\"\"\n",
    "\n",
    "  # Tokenizer for converting words to integers (assuming fitted on training data)\n",
    "  tokenizer = Tokenizer(num_words=max_features)  # Adjust max_features if needed\n",
    "\n",
    "  # Preprocess the user review\n",
    "  processed_review = [word.lower() for word in review.split()]  # Lowercase and split words\n",
    "  # Convert words to integer tokens based on the tokenizer's vocabulary\n",
    "  processed_review = tokenizer.texts_to_sequences([processed_review])\n",
    "\n",
    "  # Pad sequences to match model input length\n",
    "  processed_review = pad_sequences(processed_review, maxlen=max_len)\n",
    "\n",
    "  # Predict sentiment\n",
    "  prediction = model.predict(processed_review)\n",
    "  sentiment = \"positive\" if prediction > 0.5 else \"negative\"\n",
    "  return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "150556ac-822d-4c7c-9cf2-d6bc14a04be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your movie review:  good movie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652ms/step\n",
      "Predicted sentiment for your review: negative\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "  # Load the trained model (replace with your model loading logic)\n",
    "  # ... (model loading code from previous steps)\n",
    "\n",
    "  # Get user input review\n",
    "  user_review = input(\"Enter your movie review: \")\n",
    "\n",
    "  # Predict sentiment\n",
    "  predicted_sentiment = predict_sentiment(model, user_review)\n",
    "\n",
    "  print(\"Predicted sentiment for your review:\", predicted_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ce3e325-49da-46b5-96fd-a0c5368cdaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your movie review:  bad movie\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "Predicted sentiment for your review: negative\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "  # Load the trained model (replace with your model loading logic)\n",
    "  # ... (model loading code from previous steps)\n",
    "\n",
    "  # Get user input review\n",
    "  user_review = input(\"Enter your movie review: \")\n",
    "\n",
    "  # Predict sentiment\n",
    "  predicted_sentiment = predict_sentiment(model, user_review)\n",
    "\n",
    "  print(\"Predicted sentiment for your review:\", predicted_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe27628-f7e6-46ac-bee8-b4e312354d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
